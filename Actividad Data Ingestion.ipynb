{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkAnkZ7RPi6NIxU2iQYNYN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U6xfQMnUxo2m"
      },
      "outputs": [],
      "source": [
        "#Parte 1 importar archivos CSV\n",
        "import pandas as pd\n",
        "dataframe1 = pd.read_csv('/content/Machine-readable-business-employment-data-sep-2021-quarter.csv')\n",
        "dataframe2 = pd.read_csv('/content/annual-enterprise-survey-2020-financial-year-provisional-csv.csv')\n",
        "dataframe3 = pd.read_csv('/content/electronic-card-transactions-november-2021-csv-tables.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parte 2 Importar archivos JSON\n",
        "\n",
        "dataframe4 = pd.read_json('/content/albums.json')\n",
        "dataframe5 = pd.read_json('/content/todos.json')\n",
        "dataframe6 = pd.read_json('/content/photos.json')"
      ],
      "metadata": {
        "id": "Hiw5MGa5yBsx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parte 3 Convertir a Excel\n",
        "dataframe4.to_excel('albums.xlsx')\n",
        "dataframe5.to_excel('todos.xlsx')\n",
        "dataframe6.to_excel('photos.xlsx')\n",
        "dataframe1.to_excel('Machine.xlsx')\n",
        "dataframe2.to_excel('anuual.xlsx')\n",
        "dataframe3.to_excel('electronic.xlsx')\n",
        "\n",
        "#Convertir archivos a CSV\n",
        "dataframe4.to_csv('albums.csv')\n",
        "dataframe5.to_csv('todos.csv')\n",
        "dataframe6.to_csv('photos.csv')\n",
        "\n",
        "#Convertir archivos a JSON\n",
        "dataframe1.to_json('Machine.json')\n",
        "dataframe2.to_json('annual.json')\n",
        "dataframe3.to_json('electronic.json')"
      ],
      "metadata": {
        "id": "sbBNzY9FyNmS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parte4: Hacer pickle todos los dataframes anteriores\n",
        "import pickle\n",
        "with open ('dataframe1.pkl', 'wb') as archivo1:\n",
        "  pickle.dump(dataframe1, archivo1)\n",
        "with open ('dataframe2.pkl', 'wb') as archivo2:\n",
        "  pickle.dump(dataframe2, archivo2)\n",
        "with open ('dataframe3.pkl', 'wb') as archivo3:\n",
        "  pickle.dump(dataframe3, archivo3)\n",
        "with open ('dataframe4.pkl', 'wb') as archivo4:\n",
        "  pickle.dump(dataframe4, archivo4)\n",
        "with open ('dataframe5.pkl', 'wb') as archivo5:\n",
        "  pickle.dump(dataframe5, archivo5)\n",
        "with open ('dataframe6.pkl', 'wb') as archivo6:\n",
        "  pickle.dump(dataframe6, archivo6)"
      ],
      "metadata": {
        "id": "zZdcqeWg0Y9l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parte4: Hacer unpickle todos los archivos pickle anteriores\n",
        "with open ('dataframe1.pkl', 'rb') as archivo1:\n",
        "  dataframe1 = pickle.load(archivo1)\n",
        "with open ('dataframe2.pkl', 'rb') as archivo2:\n",
        "  dataframe2 = pickle.load(archivo2)\n",
        "with open ('dataframe3.pkl', 'rb') as archivo3:\n",
        "  dataframe3 = pickle.load(archivo3)\n",
        "with open ('dataframe4.pkl', 'rb') as archivo4:\n",
        "  dataframe4 = pickle.load(archivo4)\n",
        "with open ('dataframe5.pkl', 'rb') as archivo5:\n",
        "  dataframe5 = pickle.load(archivo5)\n",
        "with open ('dataframe6.pkl', 'rb') as archivo6:\n",
        "  dataframe6 = pickle.load(archivo6)\n"
      ],
      "metadata": {
        "id": "EYnhmP538BN6"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}